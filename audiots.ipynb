{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj3n84nSHyhP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "df = pd.read_excel(\"corpo_announcements.xlsx\") #file too big to be exhibited raw on github\n",
        "\n",
        "df['DATE'] = df['last_update'].apply(lambda x: str(x)[:10])\n",
        "relevant_columns = ['HEADLINE', 'NEWSSUB', 'MORE', 'NSURL', 'SOURCE']\n",
        "df = df[relevant_columns]\n",
        "\n",
        "\n",
        "# Identify links to transcripts and audio files using regular expressions\n",
        "transcript_regex = r'https?://.*\\.pdf'\n",
        "audio_regex = r'https?://.*\\.mp3'\n",
        "\n",
        "def extract_links(row):\n",
        "    url = row['SOURCE']\n",
        "    if re.match(transcript_regex, url):\n",
        "        row['TRANSCRIPT_LINK'] = url\n",
        "    elif re.match(audio_regex, url):\n",
        "        row['AUDIO_LINK'] = url\n",
        "    else:\n",
        "        # Download the source file if needed\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            content_type = response.headers.get('Content-Type')\n",
        "            if 'pdf' in content_type:\n",
        "                row['TRANSCRIPT_LINK'] = url\n",
        "            elif 'audio' in content_type:\n",
        "                row['AUDIO_LINK'] = url\n",
        "    return row\n",
        "\n",
        "\n",
        "df = df.apply(extract_links, axis=1)\n",
        "\n",
        "links = []\n",
        "\n",
        "# Iterate through each URL in the dataframe\n",
        "for url in df['NSURL']:\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "    # Parse the HTML content of the webpage\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Extract the links to the earnings call transcripts and audio files using regular expressions\n",
        "    transcript_link = soup.find('a', href=re.compile(transcript_regex))\n",
        "    audio_link = soup.find('a', href=re.compile(audio_regex))\n",
        "    # Add the links to the list\n",
        "    links.append({'Transcript': transcript_link['href'] if transcript_link else None, 'Audio': audio_link['href'] if audio_link else None})\n",
        "\n",
        "\n",
        "links_df = pd.DataFrame(links)\n",
        "\n",
        "\n",
        "df = pd.concat([df, links_df], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "df.to_excel(\"audio_ts.xlsx\", index=False)"
      ]
    }
  ]
}